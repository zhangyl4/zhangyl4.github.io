---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# About me
I am Yulin Zhang (张宇麟), a Master's student (2024-2027) at [ShanghaiTech University](https://www.shanghaitech.edu.cn/eng/), advised by [Prof. Sibei Yang](https://sibeiyang.github.io/). Previously, I received my Bachelor's degree from [ShanghaiTech University](https://www.shanghaitech.edu.cn/eng/) in 2024. 

I am honored to work in [SooLab](https://github.com/SooLab) during my master's studies. My research interests include 1. Spatial Intelligence, 2. Multimodal Large Language Models (LLM/MLLM), 3. Open-world Visual Understanding. Currently, I am focusing on equipping multimodal large language models with spatial reasoning abilities, particularly in 3D scene understanding, embodied navigation, and object grounding. Here is my [CV]().

<span style="color:red; font-weight:bold;">**I am always happy to communicate with people from different fields and directions. Feel free to contact me!**</span>

# 🔥 News
- *2025.09.19*: &nbsp;🎉🎉 Our paper "Eyes Wide Open: Ego Proactive Video-LLM for Streaming Video" has been accepted to NeurIPS 2025!
- *2025.07*: &nbsp;🎉🎉 Our paper "No More Sibling Rivalry: Debiasing Human-Object Interaction Detection" has been accepted to ICCV 2025!

# 📝 Publications 

\* denotes **equal contribution**

<div class='paper-box'>
  <div class='paper-box-image'>
    <div class="badge">NIPS2025</div>
    <img src='images/EyeWO.png' alt="sym" width="100%">
  </div>
  <div class='paper-box-text' markdown="1">

[Eyes Wide Open: Ego Proactive Video-LLM for Streaming Video](/publications/eyes-wide-open/)

**Yulin Zhang**, Cheng Shi, Yang Wang, Sibei Yang

[[Code]]()
  </div>
</div>


<div class='paper-box'>
  <div class='paper-box-image'>
    <div class="badge">ICCV2025</div>
    <img src='images/NMSR-HOI.png' alt="sym" width="100%">
  </div>
  <div class='paper-box-text' markdown="1">

[No More Sibling Rivalry: Debiasing Human-Object Interaction Detection](https://arxiv.org/abs/2509.00760)

Bin Yang\*, **Yulin Zhang**\*, Hong-Yu Zhou, Sibei Yang
  </div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'>
    <div class="badge">ECCV2024</div>
    <img src='images/part2object.png' alt="sym" width="100%">
  </div>
  <div class='paper-box-text' markdown="1">

[Part2Object: Hierarchical Unsupervised 3D Instance Segmentation](https://arxiv.org/abs/2407.10084)

Cheng Shi\*, **Yulin Zhang**\*, Bin Yang, Jiajin Tang, Yuexin Ma, Sibei Yang

[[Code]](https://github.com/SooLab/Part2Object)

  </div>
</div>



# ❤️ Hobbies

<span class='anchor' id='hobbies'></span>

I'm a huge 🏀 basketball fan and love watching NBA games. Stephen Curry and LeBron James are my favorite players! I also play basketball regularly to stay active and have fun.

<!-- # 🎖 Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# 📖 Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

<br><br><br><br><br>